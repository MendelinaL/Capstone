{"cells":[{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[],"cell_id":"d2025633ba6241eba7bc74284b575465","deepnote_cell_type":"text-cell-h2"},"source":"## Hate Speech Detection Through Sentiment Analysis","block_group":"d2025633ba6241eba7bc74284b575465"},{"cell_type":"markdown","metadata":{"is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":8,"fromCodePoint":0}],"cell_id":"6aa49047564d49e78e145bf724f30f73","deepnote_cell_type":"text-cell-p"},"source":"Authors:\nJohn Chen\nMendelina Lopez\nKatie Hu","block_group":"6aa49047564d49e78e145bf724f30f73"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c24603cf465742e9a41ef7e53f9f7574","deepnote_cell_type":"text-cell-h3"},"source":"### Abstract","block_group":"c24603cf465742e9a41ef7e53f9f7574"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"77c0aff8bd8c46c5829007a00b435b62","deepnote_cell_type":"text-cell-p"},"source":"With the prevalence of negativity online, the urgency to counter this stems from its real-world impact on discrimination and crime. The overall goal was to use data science methodology to create a web application that can be used for a more proactive approach by users to detect hate speech and offensive language within an average character limit post on social media. A data pipeline was built using Python to provide a web application that can detect the sentiment for hate speech and offensive language where a tweet or sentence can be tested for positive, negative, and neutral sentiment. Several models were tested including, “Long Short-Term Memory Networks” (LSTM), which had the best performance overall based on accuracy, precision, recall, F1 score, and AUC. A hate speech sentiment app was built using the LSTM model which displayed strong performances detecting negative, neutral, and positive sentiment from tweets or sentences; however, it is important to note that the app is not ready to detect sarcasm, identify nuanced usage of punctuation, or slang.","block_group":"77c0aff8bd8c46c5829007a00b435b62"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"030eee099dc7441d9b8c0abc47a5e0a4","deepnote_cell_type":"text-cell-h3"},"source":"### Background","block_group":"030eee099dc7441d9b8c0abc47a5e0a4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"e3ad97357f6d4fe9a2b6bc1dc5bb31d4","deepnote_cell_type":"text-cell-p"},"source":"The widespread use of social media has revolutionized communication and connectivity, allowing individuals to express themselves and connect with others globally. On the other hand, freedom of speech has brought the issue of an online platform that has the ability to spread hate speech and offensive language, which targets individuals or groups. Hate speech reached a high during COVID-19 when derogatory statements were aimed at individuals of the Asian community, falsely blaming them for the spread of the virus (Huang et al., 2023). Most would recall the terror as countless hate crimes resulted from this idea of blaming a whole pandemic on a specific group of people. Twitter was recently acquired by Elon Musk in October 2022. Musk self-describes himself as a “free speech absolutist” and has further made changes to Twitter policies to allow more discussions online (Frenkel & Conger, 2022). With these changes, hate speech has increasingly become more prominent. Derogatory comments and posts toward Black Americans have increased by 300%, homophobic posts have increased by 150%, and anti-Semitic posts referring to Jews or Judaism increased by more than 61% (Frenkel & Conger, 2022). With such eye-opening figures, it is apparent that social media plays a major role in society and how people think. ","block_group":"e3ad97357f6d4fe9a2b6bc1dc5bb31d4"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"61ffafdf85754b5080ec471ab64abb15","deepnote_cell_type":"text-cell-p"},"source":"Hate speech undermines equality and perpetuates discrimination both online and offline. In response to the pressing need to address this issue, organizations such as Twitter could benefit from a team of data scientists to analyze patterns and linguistic cues, ultimately leading to the development of the advanced tools and models for detecting and combating hate speech. Addressing this challenge requires a collaborative approach, involving companies, policymakers, users, and data scientists working together to develop effective solutions for mitigating hate speech and offensive language within social media platforms.","block_group":"478a66cb397f4fedba750bd88d2a0fc6"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"a5cc20d2d5a14e7e8debf5030d03cf75","deepnote_cell_type":"text-cell-h3"},"source":"### Problem Identification and Motivation","block_group":"a5cc20d2d5a14e7e8debf5030d03cf75"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"3d60c7cb48c14f9b9ac462155b787c87","deepnote_cell_type":"text-cell-p"},"source":"In seeking to address the issue of hate speech and offensive language, the goal was to mitigate such a burden to remove one factor that affects the overall mental health of social media users. This project is important to those involved either from personal experience and/or the witnessing of racist, misogynist, and homophobic posts and comments via social media platforms. Hate crimes have been acted on from what would begin as a post on Twitter. With most of the total global population on social media, hate speech is not going to disappear, so it is important for all to take a stand and find a way to counteract hate speech. The passion driving this project is the importance of reducing hate speech and offensive language and to act as a consulting group analyzing Twitter’s data in identifying tweets that would be considered negative sentiment content. Twitter and other organizations working to reduce hate speech and offensive language on social media platforms should be interested in this type of application as it would aim to create a safer online environment for users.","block_group":"3d60c7cb48c14f9b9ac462155b787c87"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"98c31486a2a54c57bb9e13c0154b8ca6","deepnote_cell_type":"text-cell-h3"},"source":"### Working Hypothesis","block_group":"98c31486a2a54c57bb9e13c0154b8ca6"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d639577bf95c43bc93f9dac87ef96c0e","deepnote_cell_type":"text-cell-p"},"source":"The working hypothesis is to develop a hate speech detection system for social media platforms by using natural language processing techniques and harnessing the power of machine learning algorithms.","block_group":"e4a03667c5ea4ec091665934bb46538b"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"cf26f39bc7b349babc632aa743f81c9c","deepnote_cell_type":"text-cell-h3"},"source":"### Objectives","block_group":"cf26f39bc7b349babc632aa743f81c9c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0545d2e5450b478d934e104a26e620f2","deepnote_cell_type":"text-cell-p"},"source":"The dataset used focused specifically on Twitter posts acquired from Kaggle. To gain insight from the data, exploratory data analysis and cleaning was performed. This project was set to convey to what extent offensive language is a problem and the possible growth at which it could go. It is critical to acknowledge that hate speech is an absolute issue that needs to be mitigated and will be addressed by further flagging users who might show an increase in negative posts. The objective of this sentiment analysis project is to detect hate speech and offensive language in tweets using past posts from Twitter. If the findings prove to be substantial, the hypothetical consulting group should be interested in creating a safer space for users online.","block_group":"0545d2e5450b478d934e104a26e620f2"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0b26f02719724d6cacf0b6861f8eef1d","deepnote_cell_type":"text-cell-h3"},"source":"### Literature Review","block_group":"0b26f02719724d6cacf0b6861f8eef1d"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c7b94787aca04932b170426881e07a0c","deepnote_cell_type":"text-cell-p"},"source":"There are several studies relating to finding specific verbiage using natural language processing (NLP) and various machine learning methods that will provide insight into a user’s posted content. The main objective of this study is to detect key terminology representing a form of hate speech and/or offensive language. Studies have focused on increased social media trends, acts of violence, and signs of distress in one’s mental health. The rise of digital interaction and past studies give insight into why it is critical to detect hate speech and offensive language.","block_group":"fb4ff1c7940e41819bbf8701b0853c08"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"f778f1e7e55f46aabc069ac81f41a099","deepnote_cell_type":"text-cell-p"},"source":"1) Race, Ethnicity, and National Origin-Based Discrimination in Social Media and Hate Crimes Across 100 U.S. Cities\nFrom a geographical focus, hate speech content posted on social media has a direct correlation to hate crimes across the top cities in the United States. The data source used is Twitter’s tweets; however, with Facebook being the leading social media platform with a denser focus on hate speech, the correlation of hate crimes in specific cities based on the tweets might have some gaps. The data source for the hate crimes uses the Federal Bureau of Investigate (FBI) crime data to determine hate crimes that have been recorded. This solution uses an n-gram based approach to feed into classification machine learning techniques (Relia et al., 2019). ","block_group":"ebd2d09fcd8e47e1845627b15e4ade23"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"de5c573b8fe343c89ac27b113426eff3","deepnote_cell_type":"text-cell-p"},"source":"\n2) Misinformation and Hate Speech: The Case of Anti-Asian Hate Speech During the COVID-19 Pandemic\nThis study identified specific cases where misinformation fueled hate speech. Following Trump’s tweets spreading COVID-19 misinformation such as calling it the “Chinese virus”, there was a massive spike of anti-Asian hate speech. The study uses the keywords “Chinese virus” to look into tweets tied to hate speech with Trump pre- and post-tweet. This solution offers a geographical focus using bidirectional encoder representations from transformers (BERT) embeddings and logistic regression to classify what tweets are associated with Trump and anti-Asian hate speech not affiliated with Trump (Kim & Kesari, 2021).","block_group":"d3db1090ab604e699a43370c247686ab"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"9fa36ca4f1174cb48974b3f8733e8d3e","deepnote_cell_type":"text-cell-p"},"source":"\n3)  Insider Threat Detection Based on NLP Word Embedding and Machine Learning\nExposure of an organization’s sensitive information can cause serious destruction of assets, resources, and integrity. With the growth of technology and the cloud, insider threat is a serious concern that needs to be detected. The solution for this problem is similar to hate speech sentiment detection in that it uses both NLP and machine learning to detect keywords relating to insider threat concerns. The approach used to flag potential threats focused on both unsupervised learning techniques such as XG Boost, KNN, LR, and NLP models such as word2vec and GloVe methods to detect insider threats with machine learning models having a higher performance than NLP (Haq et al., 2022).","block_group":"0eeeaee63261406aa39eaf9ba22b4b73"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"42c99e1ddc5a49deb5509745411f1f4a","deepnote_cell_type":"text-cell-p"},"source":"\n4) A Comparative Analysis on Word Suicidal Ideation Detection using NLP, Machine, and Deep Learning\nDeath by suicide presents a significant public health issue, and individuals often face challenges in seeking medical assistance for it. Early detection of suicidal intentions can greatly reduce death by suicide. Social media is very prominent in current societal norms, and with people sharing their feelings, views, and thoughts online. This solution focuses on feature engineering-based machine learning techniques to detect suicidal ideation to provide medical experts the detection to save lives (Haque et al., 2022).","block_group":"6a2302e54ec7468cbc6f02cc36462b5d"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2920c4494f074a06a20250954dceb1a6","deepnote_cell_type":"text-cell-p"},"source":"\n5) Autoencoder-Based Feature Extraction for Identifying Hate Speech Spreaders in Social Media\nHate speech has grown immensely with social media platforms allowing users to post content. This study seeks to identify hate speech across both English and Spanish content as users posting more hate related data are more likely to engage in violent behavior. This solution uses feature extraction that is then fed into an autoencoder to classify whether a user is a hate speech spreader or not (Kumar et al., 2023).","block_group":"8360219e19544c8eb33261157b5cc1e7"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"bf0090b6cb824b6c92a7d8ec4bfd6f68","deepnote_cell_type":"text-cell-p"},"source":"\n6) Understanding and Appraising “Hate Speech”\nHaving a corpus of hate speech specific content is essential in distinguishing hate speech and offensive language. Hate speech has significantly increased from the 1990s to present day in newspapers covering topics related to this content. This study focuses on topic modeling to identify patterns of hate speech in relation to actions, objects, legal, location, etc. The solution used is to see how hate speech is tied to a social aspect and how it is used in a legal context to the characteristics of hate speech (Vilar-Lluch, 2023).","block_group":"bffeb152243f48ff951ff6953dbfb245"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"616f1f80786d4ef1b30c76c8c2db65ba","deepnote_cell_type":"text-cell-h3"},"source":"### Methodology","block_group":"d7c4dd33d30448928b6ca78593211659"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"77c97e825f8440ba9fa449e691304c6d","deepnote_cell_type":"text-cell-p"},"source":"This project utilized text data for data science study. The process started with a solid business understanding of the problem as required by the hypothetical company. A comprehension of the data being used allowed for effectively choosing the best path to take moving forward. As a practice, the norm was expected to ensure that data is acquired ethically and with respect to privacy around sensitive information. Such a process then leads the way for text data preparation and further modeling for predictive analytics. Evaluation of the project thus far permitted the showcasing of results and adjusting as needed. Lastly, deployment of the model was the final step in the process.","block_group":"4802b99295474f6784c702bd82d5a951"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d6b24601d7e24154afd744f9b7319f1e","deepnote_cell_type":"text-cell-h3"},"source":"### Description of Data Source","block_group":"d6b24601d7e24154afd744f9b7319f1e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"5d1ca4b835bf4ea7b77646aa9e376089","deepnote_cell_type":"text-cell-p"},"source":"The data for this study was pulled from Kaggle and consists of Twitter posts that are flagged as either hate speech, offensive language, or neither. The dataset contains roughly 25,000 records with a total of seven variables (Samoshyn, 2020). The data source comes from an article done by Cornell University in 2017 and has no missing data. The seven variables are listed as the following: index, count, hate_speech, offensive_language, neither, class, and tweet. The variable class is nominal denoting a “0” for a tweet consisting of hate speech, a “1” if the post has offensive language, and “2” if neither. The class and tweet variables were primarily used for this project as it possesses vital information.","block_group":"9d6138afe84748aab10d91055542d733"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"d56840da0ab94695b737f1366450f5bf","deepnote_cell_type":"text-cell-h3"},"source":"### In Summary","block_group":"d56840da0ab94695b737f1366450f5bf"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"fa6c42bf2ab54080a56d6268ab1b05d5","deepnote_cell_type":"text-cell-p"},"source":"In current society, where the vast majority of individuals have a presence on social media platforms such as Twitter, the far-reaching impact of these platforms on people’s lives is undeniable. Unfortunately, this influence can be exploited leading to the propagation of hate speech and offensive language. It is for this reason that a great importance is placed to detect and counteract such negativity. This application can benefit social media users by creating a platform on which users can input tweet texts that can have an output of identifying whether the sentiment is positive, neutral, or negative and if hate speech and offensive language were detected within the text.","block_group":"fa6c42bf2ab54080a56d6268ab1b05d5"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"79a77d2fdda544d49a326c195caf3e1a","deepnote_cell_type":"text-cell-p"},"source":"For this project, a diverse selection of models was formulated for a comprehensive conclusion. Although many of them showed impressive results, the team ultimately chose the LSTM model since its results surpassed all other models. The LSTM model was seamlessly integrated into the hate speech sentiment application built using Streamlit.","block_group":"84e0741257624bf3bf51fef31da4162f"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"1e452be786454f88b4aaeeb03b82ea29","deepnote_cell_type":"text-cell-p"},"source":"The project’s core premise was the belief that a hate speech detection system for social media platforms could be realized through NLP techniques and capabilities of machine learning models. In conclusion, there is a working application that can detect the sentiment for hate speech and offensive language where a tweet or sentence can be tested for positive, negative, and neutral sentiment at an accuracy rate of about 89%. While this achievement is laudable, the model is not yet attuned to detect sarcasm and interpret the nuanced use of punctuation and verbiage meanings across different generations. The model and web application, while not perfect, can be used for a more proactive approach in countering hate speech and offensive language with identifying clear hate speech and offensive language. ","block_group":"67a8ee0761c049d78ce20e1252944a9a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"8e890cdc07af4c9fb6d6faedd54c3a4d","deepnote_cell_type":"text-cell-p"},"source":"As of now, the web application as a  hate speech detection system for social media platforms through use of NLP and machine learning will have the potential to help build a safer and more inclusive online community. These tools and insights developed can be leveraged for positive change on social network applications.","block_group":"de3660c90f8043c0883289546b63a3ff"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4abd328d5b2a4a08a8a62c97f8b3b432","deepnote_cell_type":"text-cell-h3"},"source":"### Limitations","block_group":"4abd328d5b2a4a08a8a62c97f8b3b432"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"787cb5bf1d6d440aabd7f6b0e322d26c","deepnote_cell_type":"text-cell-p"},"source":"Looking ahead to future studies, several steps can be taken to advance this project. Firstly, exploring the integration of a more intricate model into the application can increase its prediction accuracy. Enhancing the user interface combined with more extensive user testing will promise a more seamless user experience. Lastly, collaborate with social media platforms and see how the application performs on real-time data. As Twitter’s domain has changed the web scraping policy to be a monthly or annual monetary subscription-based plan, funding will be needed to support continuation of this project.  In summary, there is a multifaceted approach that incorporates model refinement, real-time capabilities, and user experience enhancements to shape the project’s future trajectory.","block_group":"787cb5bf1d6d440aabd7f6b0e322d26c"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"69b7f97260fe440c9828347b1797c573","deepnote_cell_type":"text-cell-h3"},"source":"### References","block_group":"56f65bcee11f4b2f820fc53ad4cabcc0"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":131,"fromCodePoint":112}],"cell_id":"c83b01c1ca6046849cc4325969e9a54c","deepnote_cell_type":"text-cell-p"},"source":"Frenkel, S., & Conger, K. (2022, December 2). Hate speech’s rise on Twitter is unprecedented, researchers find. The New York Times. https://www.nytimes.com/2022/12/02/technology/twitter-hate-speech.html","block_group":"c83b01c1ca6046849cc4325969e9a54c"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":165,"fromCodePoint":127}],"cell_id":"e9aa243da1974be8b19568e15224859f","deepnote_cell_type":"text-cell-p"},"source":"Haq, M. A., Khan, M. A. R., & Alshehri, M. (2022). Insider threat detection based on NLP word embedding and machine learning. Intelligent Automation & Soft Computing, 33(1), 619–635. https://doi.org/10.32604/iasc.2022.021430","block_group":"a90825a5239b40c29f11a1d1c60116d8"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":166,"fromCodePoint":154}],"cell_id":"11202ba6f89f4f60bccbb28aff0bdb02","deepnote_cell_type":"text-cell-p"},"source":"Haque, R., Islam, N., Islam, M., & Ahsan, M. M. (2022). A comparative analysis on word suicidal ideation detection using NLP, machine, and deep learning. Technologies, 10(3), 57. https://doi.org/10.3390/technologies10030057 ","block_group":"a064b393ecb24b57a12f4d71352a4b24"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":156,"fromCodePoint":134}],"cell_id":"b8f867c1268d4dfda25ed0e9c729d492","deepnote_cell_type":"text-cell-p"},"source":"Huang, J. T., Krupenkin, M., Rothschild, D., & Lee Cunningham, J. (2023). The cost of anti-Asian racism during the COVID-19 pandemic. Nature Human Behaviour, 7, 682–695. https://www.nature.com/articles/s41562-022-01493-6 ","block_group":"11bcec148e7140e69cfd0db4fc431ca8"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":68,"fromCodePoint":27}],"cell_id":"6872e1c6183c4e84910815243686ccc5","deepnote_cell_type":"text-cell-p"},"source":"Kemp, S. (2023, April 27). Digital 2023 April global statshot report. DataReportal. https://datareportal.com/reports/digital-2023-april-global-statshot ","block_group":"1b6e0ef078d4454398d296922af84d7f"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":164,"fromCodePoint":130}],"cell_id":"697eaf213a184a07b588cf7f2548bde6","deepnote_cell_type":"text-cell-p"},"source":"Kim, J. Y., & Kesari, A. (2021). Misinformation and Hate Speech: The Case of Anti-Asian Hate Speech During the COVID-19 Pandemic. Journal of Online Trust and Safety, 1(1). https://doi.org/10.54501/jots.v1i1.13 ","block_group":"1e4b114d07f54cf5a7d82fb51d1acbe9"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":102,"fromCodePoint":31}],"cell_id":"44ee19fb4b28409696b3a01aecf29a20","deepnote_cell_type":"text-cell-p"},"source":"Kumar, A. (2020, September 4). Micro-average & macro-average Scoring Metrics - Python - Data Analytics. Data Analytics. https://vitalflux.com/micro-average-macro-average-scoring-metrics-multi-class-classification-python/ ","block_group":"434b9aa5951c4aa19e2618804bcd339a"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":190,"fromCodePoint":140}],"cell_id":"34d52c64ac4e436cb2e2974310895d0f","deepnote_cell_type":"text-cell-p"},"source":"Kumar, G., Singh, J. P., & Singh, A. K. (2023). Autoencoder-based feature extraction for identifying hate speech spreaders in social media. IEEE Transactions on Computational Social Systems. https://doi.org/10.1109/tcss.2023.3240098 ","block_group":"aac5b338534e400c81a49d7f4db223a1"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":178,"fromCodePoint":66}],"cell_id":"7500cb98f1104a71821bdd7ca819491a","deepnote_cell_type":"text-cell-p"},"source":"Relia, K., Zhengyi, L., Cook, S., Chunara, R. (2019, January 31). Race, Ethnicity, and National Origin-based Discrimination in Social Media and Hate Crimes Across 100 U.S. Cities. Cornell University. https://arxiv.org/abs/1902.00119v1 ","block_group":"ff375c91c393435c9940bc25781eebc0"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"86b95e8a4e854d12b7435815548b0c36","deepnote_cell_type":"text-cell-p"},"source":"Samoshyn, A. (2020). Hate Speech and Offensive Language Dataset (Version V1) [Data set]. https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset ","block_group":"69a1d3934ac84beaab2f521b2e9fa9e9"},{"cell_type":"markdown","metadata":{"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":111,"fromCodePoint":68}],"cell_id":"e40240a7faf047c6b772dccce36881fc","deepnote_cell_type":"text-cell-p"},"source":"Vilar-Lluch, S. (2023). Understanding and appraising ‘hate speech.’ Journal of Language Aggression and Conflict. https://doi.org/10.1075/jlac.00082.vil","block_group":"3e906ab80b0d4eca8d61948b1a599738"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6f44fc36-cc7f-45cd-9389-e63ee21b85f6' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"5f7af2cb6bba4f659af2b617d3aef6cf","deepnote_execution_queue":[]}}